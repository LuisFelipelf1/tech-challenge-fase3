# Tech Challenge â€“ Fase 3 Â· GeraÃ§Ã£o de descriÃ§Ãµes a partir de tÃ­tulos (FLAN-T5)

**Autor:** LuÃ­s Felipe Alves  
**RM:** 363734  
**Entrega individual â€“ FIAP | PÃ³s IA para Devs**

---

## ğŸ¯ Objetivo
Treinar (fine-tuning leve) um modelo **FLAN-T5** para transformar **tÃ­tulos** de produtos em **descriÃ§Ãµes** usando uma amostra do dataset *AmazonTitles-1.3MM*.  
O projeto inclui: anÃ¡lise rÃ¡pida dos dados, baseline, **treinamento**, **avaliaÃ§Ã£o ROUGE**, exemplos â€œantes Ã— depoisâ€ e funÃ§Ã£o `responder()` para inferÃªncia.

---

## ğŸ”— Links
- ğŸ““ **Notebook no Google Colab**:  
 [ https://colab.research.google.com/drive/18PrMk-EvAcHeBcyITCqTqf195nZlfwda](https://colab.research.google.com/drive/16U41PAgNw-PDb_X-0PrypXwzdFJmxjZH)
- ğŸ’» **RepositÃ³rio GitHub**:  
  https://github.com/LuisFelipelf1/tech-challenge-fase3
- ğŸ¥ **VÃ­deo (YouTube)**: https://www.youtube.com/watch?v=PuN-b7v78V0

---

## ğŸ§± Estrutura
```
tech-challenge-fase3/
â”œâ”€ README.md                 â† este arquivo
â”œâ”€ notebook_tc3.ipynb        â† notebook completo (pipeline de treino/avaliaÃ§Ã£o)
â””â”€ requirements.txt          â† (opcional) versÃµes das libs
```

> Os **checkpoints** do modelo treinado ficam no Google Drive (nÃ£o versionados aqui).

---

## âš™ï¸ Ambiente & Requisitos

- Python 3.10+ (Colab recomendado)
- GPU: **A100** (ou similar)
- Principais bibliotecas:
  - `transformers==4.44.2`
  - `datasets==2.20.0`
  - `sentencepiece==0.2.0`
  - `evaluate==0.4.2`
  - `rouge-score==0.1.2`
  - `fsspec`, `gcsfs` (auxiliares no Colab)

InstalaÃ§Ã£o (primeira cÃ©lula do notebook):
```bash
pip -q install -U "transformers==4.44.2" "datasets==2.20.0" "sentencepiece==0.2.0"                  "evaluate==0.4.2" "rouge-score==0.1.2" fsspec gcsfs
```

---

## ğŸ“ Dados
Coloque o arquivo `trn.json` (ou `trn.json.gz`) no caminho:
```
/content/drive/MyDrive/tc3_flan_t5/raw/trn.json
```

Cada linha contÃ©m:
```json
{ "title": "Girls Ballet Tutu Neon Pink", "content": "High quality 3 layer ballet tutu..." }
```

> O notebook carrega o dataset em **streaming** e amostra um tamanho configurÃ¡vel (RÃPIDO ou COMPLETO).

---

## ğŸ—ï¸ Pipeline (resumo)
1. **Carregamento & amostragem** do `trn.json`.
2. **TokenizaÃ§Ã£o (Seq2Seq)** com prompt curto:
   ```
   Generate a concise product description.
   Title: {title}
   ```
3. **Baseline** (modelo sem ajuste) para comparaÃ§Ã£o.
4. **Fine-tuning** com `Seq2SeqTrainer` (1â€“2 Ã©pocas, batch efetivo 32).
5. **AvaliaÃ§Ã£o** com **ROUGE-1/2/L**.
6. **InferÃªncia** com `responder(title)`.

---

## â–¶ï¸ Como rodar

### No Colab (recomendado)
1. Abra o link do Colab (acima) e monte seu Google Drive.  
2. Copie `trn.json` para `/content/drive/MyDrive/tc3_flan_t5/raw/trn.json`.  
3. Escolha `MODO = "RAPIDO"` para validar ou `MODO = "COMPLETO"` para o resultado final.  
4. Execute todas as cÃ©lulas.  
5. Gere descriÃ§Ãµes:
   ```python
   responder("Girls Ballet Tutu Neon Pink")
   ```

### Local (opcional)
1. Crie um venv e instale os pacotes do `requirements.txt`.  
2. Ajuste os caminhos do Drive no notebook para uma pasta local.  
3. Execute o notebook (Jupyter/VSCode).

---

## ğŸ”§ HiperparÃ¢metros
- **Modelo:** `google/flan-t5-small` (alternativa: `flan-t5-base`)
- **Amostra:** `RÃPIDO=9000` | `COMPLETO=30000`  
- **Ã‰pocas:** `1` (RÃ¡pido) | `2` (Completo)  
- **LR:** `2e-4`  
- **Batch:** `8` | **Grad Accum:** `4` (efetivo 32)  
- **MAX_SOURCE_LEN:** `96` | **MAX_TARGET_LEN:** `192`  
- **BF16:** habilitado em A100

---

## ğŸ“Š Resultados (preencher com os seus nÃºmeros)
- **ROUGE-1:** `0.___`
- **ROUGE-2:** `0.___`
- **ROUGE-L:** `0.___`

### Antes Ã— Depois (exemplos)
- **Title:** _exemplo 1_  
  **Antes (baseline):** _â€¦_  
  **Depois (fine-tuned):** _â€¦_
- **Title:** _exemplo 2_  
  **Antes:** _â€¦_  
  **Depois:** _â€¦_

> ObservaÃ§Ã£o: como os tÃ­tulos sÃ£o curtos e as descriÃ§Ãµes longas, **ROUGE** tende a subestimar um pouco: por isso reforÃ§amos prompt objetivo e limites de geraÃ§Ã£o.

---

## ğŸ§ª Dica de teste rÃ¡pido (vÃ­deo)
```python
t = "Girls Ballet Tutu Neon Pink"
print("BASELINE :", gerar_base([t])[0])
print("FINETUNED:", responder(t))
```

---

## ğŸ“ Notas
- Pipeline nÃ£o usa `bitsandbytes/triton`, evitando conflitos de CUDA.
- Checkpoints treinados foram armazenados no Google Drive (fora do repo).
- Trabalho **individual**. Ãšltima atualizaÃ§Ã£o: 2025-10-02

---

## ğŸ“š ReferÃªncias
- Google FLAN-T5  
- Hugging Face Transformers / Datasets / Evaluate  
- ROUGE-score
